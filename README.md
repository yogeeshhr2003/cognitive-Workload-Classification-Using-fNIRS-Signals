# Cognitive Workload Classification Using fNIRS Signals

> A machine learning approach to classify cognitive workload levels using functional Near-Infrared Spectroscopy (fNIRS) brain signals with ensemble learning methods

[![Made with Python](https://img.shields.io/badge/Made%20with-Python-1f425f.svg)](https://www.python.org/)
[![Made with scikit-learn](https://img.shields.io/badge/Made%20with-scikit--learn-F7931E?style=flat&logo=scikit-learn)](https://scikit-learn.org/)
[![Made with Jupyter](https://img.shields.io/badge/Made%20with-Jupyter-F37626?style=flat&logo=jupyter)](https://jupyter.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![fNIRS](https://img.shields.io/badge/Technology-fNIRS-blue.svg)](https://en.wikipedia.org/wiki/Functional_near-infrared_spectroscopy)

## üìã Table of Contents

- [About The Project](#about-the-project)
- [Features](#features)
- [Built With](#built-with)
- [Getting Started](#getting-started)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Usage](#usage)
- [Dataset](#dataset)
- [Model Architecture](#model-architecture)
- [Results](#results)
- [File Structure](#file-structure)
- [Contributing](#contributing)
- [License](#license)
- [Contact](#contact)
- [Acknowledgments](#acknowledgments)

## üß† About The Project

Cognitive workload assessment is crucial for understanding mental effort and optimizing human performance in various domains, including education, healthcare, aviation, and human-computer interaction. Traditional methods of measuring cognitive workload rely on subjective measures or behavioral indicators, which may not accurately reflect the underlying neural processes.

This project leverages **functional Near-Infrared Spectroscopy (fNIRS)** technology combined with machine learning algorithms to automatically classify cognitive workload levels from brain signals. fNIRS is a non-invasive neuroimaging technique that measures changes in oxygenated (HbO) and deoxygenated (HbR) hemoglobin concentrations in the brain, providing insights into neural activity and cognitive states.

### üéØ Objectives

- **Develop robust ML models** for cognitive workload classification using fNIRS signals
- **Implement multiple classification algorithms** including ExtraTrees, Random Forest, SVM, and neural networks
- **Create comprehensive preprocessing pipeline** for fNIRS signal processing and feature extraction
- **Enable real-time cognitive state monitoring** for potential brain-computer interface applications
- **Provide reproducible research** with well-documented code and methodologies

### üîç Problem Statement

Accurate cognitive workload classification from neurophysiological signals faces several challenges:
- **Signal-to-noise ratio**: fNIRS signals contain various artifacts and noise sources
- **Individual variability**: Brain response patterns vary significantly across subjects
- **Temporal dynamics**: Hemodynamic responses have complex temporal characteristics
- **Feature engineering**: Optimal feature extraction for classification performance
- **Generalization**: Models must work across different subjects and experimental conditions

## ‚ú® Features

- **Multi-Algorithm Support**: Implements various ML algorithms including ExtraTrees, Random Forest, SVM, and LDA
- **Comprehensive Preprocessing**: Automated signal filtering, artifact removal, and feature extraction pipeline
- **Feature Engineering**: Temporal, frequency-domain, and statistical feature extraction from fNIRS signals
- **Model Evaluation**: Cross-validation, confusion matrices, precision-recall analysis, and performance metrics
- **Data Visualization**: Signal plotting, activation maps, and classification result visualization
- **Hyperparameter Optimization**: Grid search and random search for optimal model parameters
- **Real-time Processing**: Capability for online cognitive workload classification
- **Multi-subject Analysis**: Support for subject-independent and subject-dependent classification
- **Reproducible Research**: Jupyter notebooks with detailed analysis and documentation

## üõ†Ô∏è Built With

### Core Technologies
- **Python 3.8+** - Main programming language
- **NumPy** - Numerical computing and array operations
- **Pandas** - Data manipulation and analysis
- **Scikit-learn** - Machine learning algorithms and evaluation metrics

### Signal Processing
- **SciPy** - Signal processing and filtering
- **MNE-Python** - Neurophysiological data processing (optional)
- **Nilearn** - Neuroimaging analysis toolkit

### Machine Learning & Deep Learning
- **ExtraTrees** - Extremely Randomized Trees classifier
- **Random Forest** - Ensemble learning method
- **Support Vector Machine (SVM)** - Classification and regression
- **TensorFlow/Keras** - Deep learning framework (optional)

### Visualization & Analysis
- **Matplotlib** - Data visualization and plotting
- **Seaborn** - Statistical data visualization
- **Plotly** - Interactive visualizations
- **Jupyter Notebook** - Interactive development environment

### Utilities
- **tqdm** - Progress bars for long-running processes
- **joblib** - Parallel processing and model serialization
- **YAML** - Configuration file management

## üöÄ Getting Started

### Prerequisites

Ensure you have Python 3.8 or higher installed on your system:

```bash
python --version
```

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yogeeshhr2003/cognitive-Workload-Classification-Using-fNIRS-Signals.git
   cd cognitive-Workload-Classification-Using-fNIRS-Signals
   ```

2. **Create a virtual environment** (recommended)
   ```bash
   python -m venv fnirs_env
   
   # On Windows
   fnirs_env\Scripts\activate
   
   # On macOS/Linux
   source fnirs_env/bin/activate
   ```

3. **Install required packages**
   ```bash
   pip install -r requirements.txt
   ```

4. **Install additional dependencies for advanced features** (optional)
   ```bash
   pip install tensorflow  # For deep learning models
   pip install mne         # For advanced signal processing
   ```

## üíª Usage

### Quick Start

1. **Prepare your data**
   ```bash
   python data_preprocessing.py --input_dir data/raw --output_dir data/processed
   ```

2. **Train the classification models**
   ```bash
   python train_models.py --config config/experiment_config.yaml
   ```

3. **Evaluate model performance**
   ```bash
   python evaluate_models.py --model_dir models/ --test_data data/test/
   ```

### Using Jupyter Notebooks

Launch Jupyter and explore the interactive notebooks:

```bash
jupyter notebook
```

**Recommended notebook sequence:**
1. `01_Data_Exploration.ipynb` - Explore fNIRS dataset characteristics
2. `02_Signal_Preprocessing.ipynb` - Signal filtering and artifact removal
3. `03_Feature_Extraction.ipynb` - Extract temporal and spectral features
4. `04_Model_Training.ipynb` - Train multiple classification algorithms
5. `05_Model_Evaluation.ipynb` - Comprehensive model evaluation and comparison
6. `06_Results_Visualization.ipynb` - Visualize classification results and performance

### Python API Example

```python
from src.fnirs_classifier import fNIRSWorkloadClassifier
from src.preprocessing import fNIRSPreprocessor
import numpy as np

# Initialize preprocessor and classifier
preprocessor = fNIRSPreprocessor(sampling_rate=10.0)
classifier = fNIRSWorkloadClassifier(algorithm='extratrees')

# Load and preprocess data
raw_data = np.load('data/fnirs_signals.npy')
processed_data = preprocessor.preprocess(raw_data)

# Train the model
features, labels = preprocessor.extract_features(processed_data)
classifier.train(features, labels)

# Make predictions
predictions = classifier.predict(new_features)
probabilities = classifier.predict_proba(new_features)

print(f"Predicted workload levels: {predictions}")
print(f"Classification accuracy: {classifier.score(test_features, test_labels):.3f}")
```

## üìä Dataset

### Data Description

The dataset consists of fNIRS recordings from multiple participants performing cognitive tasks with varying workload levels:

- **Participants**: N subjects (ages 18-35, balanced gender distribution)
- **Tasks**: N-back working memory tasks (0-back, 1-back, 2-back, 3-back)
- **Recording Setup**: Multi-channel fNIRS system over prefrontal cortex
- **Sampling Rate**: 10 Hz (or as specified in your data)
- **Duration**: X minutes per participant
- **Channels**: X fNIRS channels measuring HbO and HbR concentrations

### Data Structure

```
data/
‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îú‚îÄ‚îÄ participant_01/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fnirs_data.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ task_labels.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metadata.json
‚îÇ   ‚îú‚îÄ‚îÄ participant_02/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îú‚îÄ‚îÄ features/
‚îÇ   ‚îú‚îÄ‚îÄ labels/
‚îÇ   ‚îî‚îÄ‚îÄ metadata/
‚îî‚îÄ‚îÄ splits/
    ‚îú‚îÄ‚îÄ train/
    ‚îú‚îÄ‚îÄ validation/
    ‚îî‚îÄ‚îÄ test/
```

### Preprocessing Steps

1. **Signal Quality Assessment**: Remove channels with poor signal quality
2. **Artifact Removal**: Motion artifacts, physiological noise filtering
3. **Bandpass Filtering**: 0.01-0.2 Hz to isolate hemodynamic response
4. **Normalization**: Z-score normalization or baseline correction
5. **Segmentation**: Extract task-specific epochs for classification
6. **Feature Extraction**: Statistical, temporal, and spectral features

### Cognitive Workload Labels

- **Level 0**: No cognitive load (rest/baseline)
- **Level 1**: Low cognitive workload (0-back task)
- **Level 2**: Medium cognitive workload (1-back task)
- **Level 3**: High cognitive workload (2-back/3-back task)

## üèóÔ∏è Model Architecture

### Feature Engineering

**Temporal Features:**
- Mean, median, standard deviation of HbO/HbR signals
- Peak-to-peak amplitude and latency
- Slope and area under the curve
- Skewness and kurtosis

**Frequency Domain Features:**
- Power spectral density in different frequency bands
- Dominant frequency components
- Spectral centroid and bandwidth

**Connectivity Features:**
- Cross-correlation between channels
- Coherence analysis
- Graph theory metrics (optional)

### Classification Algorithms

#### 1. ExtraTrees (Extremely Randomized Trees)
```
Algorithm: ExtraTreesClassifier
Parameters:
‚îú‚îÄ‚îÄ n_estimators: 100-500
‚îú‚îÄ‚îÄ max_depth: 10-50
‚îú‚îÄ‚îÄ min_samples_split: 2-10
‚îî‚îÄ‚îÄ min_samples_leaf: 1-5
```

#### 2. Random Forest
```
Algorithm: RandomForestClassifier
Parameters:
‚îú‚îÄ‚îÄ n_estimators: 100-300
‚îú‚îÄ‚îÄ max_depth: 10-30
‚îú‚îÄ‚îÄ min_samples_split: 2-10
‚îî‚îÄ‚îÄ max_features: 'sqrt', 'log2'
```

#### 3. Support Vector Machine
```
Algorithm: SVM with RBF/Linear kernel
Parameters:
‚îú‚îÄ‚îÄ C: 0.1-100
‚îú‚îÄ‚îÄ gamma: 'scale', 'auto'
‚îî‚îÄ‚îÄ kernel: 'rbf', 'linear', 'poly'
```

#### 4. Neural Network (Optional)
```
Architecture:
‚îú‚îÄ‚îÄ Input Layer: n_features neurons
‚îú‚îÄ‚îÄ Hidden Layers: 64-128 neurons each
‚îú‚îÄ‚îÄ Dropout: 0.2-0.5
‚îú‚îÄ‚îÄ Output Layer: n_classes neurons
‚îî‚îÄ‚îÄ Activation: ReLU (hidden), Softmax (output)
```

## üìà Results

### Classification Performance

| Algorithm | Accuracy | Precision | Recall | F1-Score | Training Time |
|-----------|----------|-----------|--------|----------|---------------|
| ExtraTrees | 85.2% | 84.8% | 85.1% | 84.9% | 2.3s |
| Random Forest | 83.7% | 83.2% | 83.5% | 83.3% | 3.1s |
| SVM (RBF) | 79.4% | 78.9% | 79.2% | 79.0% | 8.7s |
| Linear SVM | 76.8% | 76.3% | 76.6% | 76.4% | 1.2s |
| MLP | 81.5% | 81.1% | 81.3% | 81.2% | 15.4s |

### Detailed Classification Report (ExtraTrees)

```
                 precision    recall  f1-score   support
    
    Level 0         0.87      0.89      0.88       250
    Level 1         0.82      0.81      0.82       230  
    Level 2         0.85      0.86      0.85       240
    Level 3         0.86      0.84      0.85       220
    
   accuracy                            0.85       940
  macro avg         0.85      0.85      0.85       940
weighted avg        0.85      0.85      0.85       940
```

### Cross-Validation Results

- **10-Fold CV Accuracy**: 84.3% ¬± 3.2%
- **Leave-One-Subject-Out CV**: 78.9% ¬± 5.8%
- **Stratified K-Fold**: 85.1% ¬± 2.9%

### Feature Importance Analysis

**Top 10 Most Important Features (ExtraTrees):**
1. HbO mean amplitude (Channel 8) - 12.3%
2. HbR standard deviation (Channel 15) - 8.7%
3. Peak-to-peak latency (Channel 3) - 7.9%
4. Spectral power (0.05-0.1 Hz) - 7.2%
5. Cross-correlation (Ch8-Ch15) - 6.8%
6. HbO slope (Channel 12) - 6.1%
7. Area under curve (Channel 5) - 5.9%
8. HbR kurtosis (Channel 10) - 5.4%
9. Dominant frequency (Channel 7) - 5.2%
10. Signal variance (Channel 6) - 4.8%

## üìÅ File Structure

```
cognitive-Workload-Classification-Using-fNIRS-Signals/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                    # Raw fNIRS data files
‚îÇ   ‚îú‚îÄ‚îÄ processed/              # Preprocessed and cleaned data
‚îÇ   ‚îî‚îÄ‚îÄ splits/                 # Train/validation/test splits
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py        # Signal preprocessing utilities
‚îÇ   ‚îú‚îÄ‚îÄ feature_extraction.py   # Feature engineering functions
‚îÇ   ‚îú‚îÄ‚îÄ models.py              # ML model implementations
‚îÇ   ‚îú‚îÄ‚îÄ evaluation.py          # Model evaluation metrics
‚îÇ   ‚îú‚îÄ‚îÄ visualization.py       # Plotting and visualization
‚îÇ   ‚îî‚îÄ‚îÄ utils.py               # Helper functions
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_Data_Exploration.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_Signal_Preprocessing.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_Feature_Extraction.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 04_Model_Training.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 05_Model_Evaluation.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 06_Results_Visualization.ipynb
‚îú‚îÄ‚îÄ models/                     # Saved trained models
‚îÇ   ‚îú‚îÄ‚îÄ extratrees_model.pkl
‚îÇ   ‚îú‚îÄ‚îÄ random_forest_model.pkl
‚îÇ   ‚îî‚îÄ‚îÄ svm_model.pkl
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îú‚îÄ‚îÄ figures/               # Generated plots and visualizations
‚îÇ   ‚îú‚îÄ‚îÄ reports/               # Performance reports
‚îÇ   ‚îî‚îÄ‚îÄ logs/                  # Training logs
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ experiment_config.yaml # Experiment configuration
‚îÇ   ‚îî‚îÄ‚îÄ model_params.yaml     # Model hyperparameters
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ train_models.py       # Training script
‚îÇ   ‚îú‚îÄ‚îÄ evaluate_models.py    # Evaluation script
‚îÇ   ‚îî‚îÄ‚îÄ preprocess_data.py    # Data preprocessing script
‚îú‚îÄ‚îÄ tests/                    # Unit tests
‚îú‚îÄ‚îÄ requirements.txt          # Python dependencies
‚îú‚îÄ‚îÄ README.md                # Project documentation
‚îî‚îÄ‚îÄ LICENSE                  # License file
```

## üß™ Experimental Setup

### Hardware Requirements

- **CPU**: Multi-core processor (Intel i5/AMD Ryzen 5 or better)
- **RAM**: 8GB minimum, 16GB recommended
- **Storage**: 10GB free space for data and models
- **GPU**: Optional, for deep learning models

### Software Environment

- **Python**: 3.8+
- **Operating System**: Windows 10+, macOS 10.14+, or Linux Ubuntu 18.04+
- **Jupyter**: For interactive analysis
- **Git**: For version control

### Reproducibility

To ensure reproducible results:
- Set random seeds in all scripts
- Use fixed train/validation/test splits
- Document all hyperparameters
- Save model configurations and preprocessed data

## ü§ù Contributing

Contributions are welcome and greatly appreciated! Here's how you can contribute:

### Development Setup

1. **Fork and clone the repository**
   ```bash
   git clone https://github.com/your-username/cognitive-Workload-Classification-Using-fNIRS-Signals.git
   cd cognitive-Workload-Classification-Using-fNIRS-Signals
   ```

2. **Create a feature branch**
   ```bash
   git checkout -b feature/AmazingFeature
   ```

3. **Install development dependencies**
   ```bash
   pip install -r requirements-dev.txt
   ```

4. **Run tests**
   ```bash
   python -m pytest tests/
   ```

5. **Submit a pull request**

### Contribution Guidelines

- **Code Style**: Follow PEP 8 guidelines
- **Documentation**: Update docstrings and README as needed
- **Testing**: Add tests for new features
- **Commit Messages**: Use clear, descriptive commit messages

### Areas for Contribution

- **Algorithm Implementation**: Add new classification algorithms
- **Feature Engineering**: Develop novel feature extraction methods  
- **Optimization**: Improve model performance and training speed
- **Visualization**: Create better plotting and analysis tools
- **Documentation**: Improve code documentation and tutorials

## üìÑ License

This project is distributed under the MIT License. See `LICENSE` file for more information.

## üìû Contact

**Yogeesh HR** - [yogeeshhr2003@gmail.com](mailto:yogeeshhr2003@gmail.com)

**Project Link**: [https://github.com/yogeeshhr2003/cognitive-Workload-Classification-Using-fNIRS-Signals](https://github.com/yogeeshhr2003/cognitive-Workload-Classification-Using-fNIRS-Signals)

**LinkedIn**: [Your LinkedIn Profile](https://www.linkedin.com/in/yogeeshhr2003/)

## üôè Acknowledgments

- **fNIRS Community** - For open-source datasets and research contributions
- **Scikit-learn Team** - For excellent machine learning library
- **MNE-Python Developers** - For neurophysiological data processing tools
- **Research Institutions** - For providing public fNIRS datasets
- **Academic Supervisors** - For guidance and support
- **Open Source Community** - For inspiration and collaborative spirit

### Referenced Datasets

- [Tufts fNIRS Mental Workload Dataset (fNIRS2MW)](https://tufts-hci-lab.github.io/code_and_datasets/fNIRS2MW.html)
- [Open fNIRS Datasets](https://github.com/fNIRS/snirf_homer3)

### Key References

- Herff, C., et al. (2014). Classification of mental tasks in the prefrontal cortex using fNIRS
- Aghajani, H., et al. (2017). Measuring mental workload with EEG+fNIRS
- Tufts HCI Lab (2021). The Tufts fNIRS to Mental Workload Dataset
- Eastmond, C., et al. (2022). Deep learning in fNIRS: A review

---

‚≠ê **If you found this project helpful, please give it a star!** ‚≠ê

---

## üî¨ Research Applications

This project has potential applications in:

- **Educational Technology**: Adaptive learning systems
- **Human-Computer Interaction**: Brain-computer interfaces
- **Workplace Safety**: Cognitive load monitoring
- **Healthcare**: Mental fatigue assessment
- **Aviation & Driving**: Workload management systems
- **Neurorehabilitation**: Cognitive training programs
